{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "401f94e7",
   "metadata": {},
   "source": [
    "# NPZ Converter\n",
    "\n",
    "This notebook converts legacy data to `.duckdb` databases to make easier to manipulate the data. The dataset is expected to have the following structure\n",
    "- /dataset_name\n",
    "    - file1.npz\n",
    "    -  file2.npz\n",
    "    - /references\n",
    "        - file1.pic.gz\n",
    "        - file2.pic.gz\n",
    "\n",
    "The data in the npz files is mapped to the `data` table and the `refrences` files are mapped to the `model_refrences` table.\n",
    "\n",
    "The `.npz` files must have the following structure:\n",
    "- `etBins`: Array of floats with the et binning limits\n",
    "- `etaBins`: Array of floats with the eta binning limits\n",
    "- `etBinIdx`: Index of the bin used for this data\n",
    "- `etaBinIdx`: Index of the bin used for this data\n",
    "- `ordered_features`: Ignored\n",
    "- `data_float`: 2D array of floats with the data\n",
    "- `data_bool`: 2D array of bools with the data\n",
    "- `data_int`: 2D array of ints with the data\n",
    "- `data_object`: 2D array of objects with the data\n",
    "- `features_float`: Array with the column names in `data_float`\n",
    "- `features_bool`: Array with the column names in `data_bool`\n",
    "- `features_int`: Array with the column names in `data_int`\n",
    "- `features_object`: Array with the column names in `data_object`\n",
    "- `target`: Array with the target\n",
    "- `protocol`: Ignored\n",
    "- `allow_pickle`: Ignored\n",
    "\n",
    "The `.pic.gz` files must have the following structure:\n",
    "- `class`: Ignored\n",
    "- `__module`: Ignored\n",
    "- `etBinIdx`: Array with 1 element representing the et bin used for this data\n",
    "- `etBins`: Array of floats with the et binning limits\n",
    "- `etaBinIdx`: Array with 1 element representing the eta bin used for this data\n",
    "- `etaBins`: Array of floats with the eta binning limits\n",
    "- `__version`: Ignored\n",
    "- `bkgRef`: Dict\n",
    "- `sgnRef`: Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f03209ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pickle\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import duckdb\n",
    "import gzip\n",
    "from io import BytesIO\n",
    "from collections import defaultdict\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53b701f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path.home() / 'data' / 'cern'\n",
    "dataset_name = 'data17_13TeV.AllPeriods.sgn.probes_lhvloose_EGAM1.bkg.vprobes_vlhvloose_EGAM7.GRL_v97.25bins'\n",
    "dataset_dir = data_dir / dataset_name\n",
    "output_file = data_dir / f'{dataset_name}.duckdb'\n",
    "references_dir = dataset_dir / 'references'\n",
    "feature_types = ['int', 'float', 'object', 'bool']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "779c571d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_table_exists(con, table_name):\n",
    "    \"\"\"\n",
    "    Checks if a table exists in the DuckDB database.\n",
    "\n",
    "    Args:\n",
    "        con: A DuckDB connection object.\n",
    "        table_name: The name of the table to check.\n",
    "\n",
    "    Returns:\n",
    "        True if the table exists, False otherwise.\n",
    "    \"\"\"\n",
    "    query = f\"SELECT EXISTS (SELECT 1 FROM information_schema.tables WHERE table_name = '{table_name}')\"\n",
    "    result = con.execute(query).fetchone()[0]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "401271c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-17T23:21:14.581434 - Processing file 1: /root/data/cern/data17_13TeV.AllPeriods.sgn.probes_lhvloose_EGAM1.bkg.vprobes_vlhvloose_EGAM7.GRL_v97.25bins/data17_13TeV.AllPeriods.sgn.probes_lhvloose_EGAM1.bkg.vprobes_vlhvloose_EGAM7.GRL_v97.25bins_et2_eta4.npz\n",
      "2025-08-17T23:21:17.431725 - Processing file 2: /root/data/cern/data17_13TeV.AllPeriods.sgn.probes_lhvloose_EGAM1.bkg.vprobes_vlhvloose_EGAM7.GRL_v97.25bins/data17_13TeV.AllPeriods.sgn.probes_lhvloose_EGAM1.bkg.vprobes_vlhvloose_EGAM7.GRL_v97.25bins_et1_eta3.npz\n",
      "2025-08-17T23:21:36.787462 - Processing file 3: /root/data/cern/data17_13TeV.AllPeriods.sgn.probes_lhvloose_EGAM1.bkg.vprobes_vlhvloose_EGAM7.GRL_v97.25bins/data17_13TeV.AllPeriods.sgn.probes_lhvloose_EGAM1.bkg.vprobes_vlhvloose_EGAM7.GRL_v97.25bins_et1_eta4.npz\n",
      "2025-08-17T23:21:44.372246 - Processing file 4: /root/data/cern/data17_13TeV.AllPeriods.sgn.probes_lhvloose_EGAM1.bkg.vprobes_vlhvloose_EGAM7.GRL_v97.25bins/data17_13TeV.AllPeriods.sgn.probes_lhvloose_EGAM1.bkg.vprobes_vlhvloose_EGAM7.GRL_v97.25bins_et2_eta0.npz\n",
      "2025-08-17T23:22:21.418387 - Processing file 5: /root/data/cern/data17_13TeV.AllPeriods.sgn.probes_lhvloose_EGAM1.bkg.vprobes_vlhvloose_EGAM7.GRL_v97.25bins/data17_13TeV.AllPeriods.sgn.probes_lhvloose_EGAM1.bkg.vprobes_vlhvloose_EGAM7.GRL_v97.25bins_et2_eta3.npz\n",
      "2025-08-17T23:22:55.265972 - Processing file 6: /root/data/cern/data17_13TeV.AllPeriods.sgn.probes_lhvloose_EGAM1.bkg.vprobes_vlhvloose_EGAM7.GRL_v97.25bins/data17_13TeV.AllPeriods.sgn.probes_lhvloose_EGAM1.bkg.vprobes_vlhvloose_EGAM7.GRL_v97.25bins_et3_eta3.npz\n",
      "2025-08-17T23:23:23.609659 - Processing file 7: /root/data/cern/data17_13TeV.AllPeriods.sgn.probes_lhvloose_EGAM1.bkg.vprobes_vlhvloose_EGAM7.GRL_v97.25bins/data17_13TeV.AllPeriods.sgn.probes_lhvloose_EGAM1.bkg.vprobes_vlhvloose_EGAM7.GRL_v97.25bins_et0_eta0.npz\n",
      "2025-08-17T23:23:35.929896 - Processing file 8: /root/data/cern/data17_13TeV.AllPeriods.sgn.probes_lhvloose_EGAM1.bkg.vprobes_vlhvloose_EGAM7.GRL_v97.25bins/data17_13TeV.AllPeriods.sgn.probes_lhvloose_EGAM1.bkg.vprobes_vlhvloose_EGAM7.GRL_v97.25bins_et0_eta2.npz\n",
      "2025-08-17T23:23:40.736843 - Processing file 9: /root/data/cern/data17_13TeV.AllPeriods.sgn.probes_lhvloose_EGAM1.bkg.vprobes_vlhvloose_EGAM7.GRL_v97.25bins/data17_13TeV.AllPeriods.sgn.probes_lhvloose_EGAM1.bkg.vprobes_vlhvloose_EGAM7.GRL_v97.25bins_et4_eta4.npz\n",
      "2025-08-17T23:23:46.295909 - Processing file 10: /root/data/cern/data17_13TeV.AllPeriods.sgn.probes_lhvloose_EGAM1.bkg.vprobes_vlhvloose_EGAM7.GRL_v97.25bins/data17_13TeV.AllPeriods.sgn.probes_lhvloose_EGAM1.bkg.vprobes_vlhvloose_EGAM7.GRL_v97.25bins_et3_eta1.npz\n",
      "2025-08-17T23:24:15.294051 - Processing file 11: /root/data/cern/data17_13TeV.AllPeriods.sgn.probes_lhvloose_EGAM1.bkg.vprobes_vlhvloose_EGAM7.GRL_v97.25bins/data17_13TeV.AllPeriods.sgn.probes_lhvloose_EGAM1.bkg.vprobes_vlhvloose_EGAM7.GRL_v97.25bins_et4_eta3.npz\n",
      "2025-08-17T23:24:42.996999 - Processing file 12: /root/data/cern/data17_13TeV.AllPeriods.sgn.probes_lhvloose_EGAM1.bkg.vprobes_vlhvloose_EGAM7.GRL_v97.25bins/data17_13TeV.AllPeriods.sgn.probes_lhvloose_EGAM1.bkg.vprobes_vlhvloose_EGAM7.GRL_v97.25bins_et3_eta0.npz\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "dataframes = []\n",
    "with duckdb.connect(str(output_file)) as con:\n",
    "    for i, filepath in enumerate(dataset_dir.glob('*.npz')):\n",
    "        print(f'{datetime.now().isoformat()} - Processing file {i + 1}: {filepath}')\n",
    "        npz_file = np.load(filepath)\n",
    "        feature_dfs = []\n",
    "        for feature_type in feature_types:\n",
    "            array_key = f'data_{feature_type}'\n",
    "            schema_key = f'features_{feature_type}'\n",
    "            feature_dfs.append(\n",
    "                pl.from_numpy(\n",
    "                    npz_file[array_key],\n",
    "                    schema=npz_file[schema_key].tolist(),\n",
    "                orient='row'\n",
    "                )\n",
    "            )\n",
    "        aux_df = pl.concat(feature_dfs, how='horizontal')\n",
    "        if i ==0 and not check_table_exists(con, 'data'):\n",
    "            con.execute(\"CREATE TABLE IF NOT EXISTS data AS SELECT * FROM aux_df\")\n",
    "        else:\n",
    "            con.execute(\"INSERT INTO data SELECT * FROM aux_df\")\n",
    "        del aux_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71805059",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_schema = pl.Schema({\n",
    "    'et_bin_lower': pl.Float32(),\n",
    "    'et_bin_upper': pl.Float32(),\n",
    "    'eta_bin_lower': pl.Float32(),\n",
    "    'eta_bin_upper': pl.Float32(),\n",
    "    'pid': pl.String(),\n",
    "    'label': pl.UInt8(),\n",
    "    'total': pl.Int64(),\n",
    "    'passed': pl.Int64(),\n",
    "    'reference': pl.String(),\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29492ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_data = defaultdict(list)\n",
    "for i, filepath in enumerate(references_dir.glob('*.pic.gz')):\n",
    "    # if i > 0:\n",
    "    #     break\n",
    "    print(f'Processing reference file {i + 1}: {filepath}')\n",
    "    with gzip.open(filepath, 'rb') as f:\n",
    "        data = pickle.load(BytesIO(f.read()))\n",
    "    et_bin_idx = data['etBinIdx']\n",
    "    eta_bin_idx = data['etaBinIdx']\n",
    "    for label, data_type in enumerate(['bkgRef', 'sgnRef']):\n",
    "        for pid, pid_data in data[data_type].items():\n",
    "            table_data['et_bin_lower'].append(float(data['etBins'][et_bin_idx]))\n",
    "            table_data['et_bin_upper'].append(float(data['etBins'][et_bin_idx + 1]))\n",
    "            table_data['eta_bin_lower'].append(float(data['etaBins'][eta_bin_idx]))\n",
    "            table_data['eta_bin_upper'].append(float(data['etaBins'][eta_bin_idx + 1]))\n",
    "            table_data['pid'].append(str(pid))\n",
    "            table_data['label'].append(int(label))\n",
    "            table_data['total'].append(int(pid_data['total']))\n",
    "            table_data['passed'].append(int(pid_data['passed']))\n",
    "            table_data['reference'].append(str(pid_data['reference']))\n",
    "reference_df = pl.from_dict(\n",
    "    dict(table_data),\n",
    "    schema=reference_schema\n",
    ")\n",
    "reference_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf472c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "with duckdb.connect(str(output_file)) as con:\n",
    "    if not check_table_exists(con, 'model_references'):\n",
    "        con.execute(\"CREATE TABLE IF NOT EXISTS model_references AS SELECT * FROM reference_df\")\n",
    "    else:\n",
    "        con.execute(\"INSERT INTO model_references SELECT * FROM reference_df\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
